{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows an exercise for a classification problem solved as part of the Artificial Intelligence Project Management course from Duke University on Coursera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee391dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747e1b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AT      V       AP     RH      PE\n",
      "0  14.96  41.76  1024.07  73.17  463.26\n",
      "1  25.18  62.96  1020.04  59.08  444.37\n",
      "2   5.11  39.40  1012.16  92.14  488.56\n",
      "3  20.86  57.32  1010.24  76.64  446.48\n",
      "4  10.82  37.50  1009.23  96.62  473.90\n",
      "5  26.27  59.44  1012.23  58.77  443.67\n",
      "6  15.89  43.96  1014.02  75.24  467.35\n",
      "7   9.48  44.71  1019.12  66.43  478.42\n",
      "8  14.64  45.00  1021.78  41.25  475.98\n",
      "9  11.74  43.56  1015.14  70.72  477.50\n",
      "shape: (9568, 5)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "file_path = \"data/CCPP_data.csv\"\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "print(df.head(10))\n",
    "print(f\"shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c87028",
   "metadata": {},
   "source": [
    "In this project we will build a model to **predict the electrical energy output** of a \n",
    "**Combined Cycle Power Plant**, which uses a combination of gas turbines, steam turbines, and heat recovery steam generators to generate power.  We have a set of 9568 hourly average ambient environmental readings from sensors at the power plant which we will use in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e054731",
   "metadata": {},
   "source": [
    "The columns in the data consist of hourly average ambient variables:\n",
    "- Temperature (T) in the range 1.81°C to 37.11°C,\n",
    "- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "- Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "- Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "- Net hourly electrical energy output (PE) 420.26-495.76 MW (**Target we are trying to predict**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e50685",
   "metadata": {},
   "source": [
    "To complete the project, you must complete each of the below steps in the modeling process.  \n",
    "\n",
    "1) For the problem described in the Project Topic section above, determine what type of machine learning approach is needed and select an appropriate output metric to evaluate performance in accomplishing the task.\n",
    "\n",
    "2) Determine which possible features we may want to use in the model, and identify the different algorithms we might consider.\n",
    "\n",
    "3) Split your data to create a test set to evaluate the performance of your final model.  Then, using your training set, determine a validation strategy for comparing different models - a fixed validation set or cross-validation.  Depending on whether you are using Excel, Python or AutoML for your model building, you may need to manually split your data to create the test set and validation set / cross validation folds.\n",
    "\n",
    "4) Use your validation approach to compare at least two different models (which may be either 1) different algorithms, 2) the same algorithm with different combinations of features, or 3) the same algorithm and features with different values for hyperparameters).  From among the models you compare, select the model with the best performance on your validation set as your final model.\n",
    "\n",
    "5) Evaluate the performance of your final model using the output metric you defined earlier. \n",
    "\n",
    "Note: data can be obtained at https://storage.googleapis.com/aipi_datasets/CCPP_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f9be3",
   "metadata": {},
   "source": [
    "### Set up vectors\n",
    "\n",
    "First, let's create the input and output vectors and separate the data into 3 sets:\n",
    "- training (train), 70%\n",
    "- cross validation (cv), 20% \n",
    "- and test 10%\n",
    "\n",
    "### 3) Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "801f9c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate 6697 == 6698.0\n",
      "Validate 1914 == 1914.0\n",
      "Validate 957 == 957.0\n"
     ]
    }
   ],
   "source": [
    "# Let's create 3 data sets using scikit-learn train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# first, we'll use a temp set that we'll then split into cv and test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df.drop('PE', axis=1), df['PE'], test_size=0.3, random_state=42)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "# Let's validate the size of the data sets (number of samples and then number of features)\n",
    "assert X_train.shape[0] + X_cv.shape[0] + X_test.shape[0] == df.shape[0]\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_cv.shape[0] == y_cv.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "assert X_train.shape[1] == df.shape[1] - 1\n",
    "\n",
    "# validate size of sets:\n",
    "print(f\"Validate {X_train.shape[0]} == {round(df.shape[0]*0.7,0)}\")\n",
    "print(f\"Validate {X_cv.shape[0]} == {round(df.shape[0]*0.2,0)}\")\n",
    "print(f\"Validate {X_test.shape[0]} == {round(df.shape[0]*0.1,0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e78c9c",
   "metadata": {},
   "source": [
    "### 1-2) Modeling approach\n",
    "\n",
    "We know that this model needs to **predict an output**, not classify one, which clearly rules out classifying algorithms.\n",
    "\n",
    "#### Feature selection\n",
    "\n",
    "To define what features to use, however, we need to gain some insight into the problem. If we look at the source information, we can gather that \"The base load operation of a power plant is influenced by four main parameters: ambient temperature, atmospheric pressure, relative humidity, and exhaust steam pressure\". This means that **all 4 features are relevant to the problem**.\n",
    "\n",
    "#### Model Selection\n",
    "\n",
    "As this is a prediction model, it makes sense to start evaluating a **Linear Regression** model to define as the standard against which to compare other models. We should also evaluate the performance of tree-based models, like **random forest** and **XGBoost**. To compare the improvement that these last two models present vis a vis a simple **Decision Tree**, it is not a bad idea to evaluate this model also.\n",
    "\n",
    "#### Model evaluation\n",
    "\n",
    "In terms of the model evaluation, we know that we need to measure the error between the prediction of our model and the actual data in the cross validation and test sets. We can expect the solution to be affected by outliers, so we should **prefer a measure of error like MSE**. The user might also get a clearer idea of the error in terms of the deviation in MW given that he/she knows the capacity of the generator. However, for someone not familiar with the generator, a percentage error metric like MAPE can be more revealing. We should probably also use **R-squared** to determine how much of the variability of the target variable (y) is not captured by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e181538",
   "metadata": {},
   "source": [
    "### 4) Model Comparison\n",
    "\n",
    "Let's start with **Linear Regression** using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be40d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE linear_regression: 21.13\n",
      "R-squared linear regression: 0.93\n",
      "MAPE linear regression: 0.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# let's train the model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# now, we'll predict the values for the output with the cross validation set\n",
    "y_hat_lr = lin_reg.predict(X_cv)\n",
    "\n",
    "# and now we can evaluate the MSE and R-squared for the prediction\n",
    "mse_lin_reg = (np.square(y_hat_lr - y_cv)).mean(axis=0)\n",
    "r_2_lin_reg = np.corrcoef(y_cv,y_hat_lr)[0,1]**2\n",
    "mape_lin_reg = mean_absolute_percentage_error(y_cv,y_hat_lr)\n",
    "\n",
    "print(f\"MSE linear_regression: {mse_lin_reg:.2f}\")\n",
    "print(f\"R-squared linear regression: {r_2_lin_reg:.2f}\")\n",
    "print(f\"MAPE linear regression: {mape_lin_reg:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b40d20",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "We will evaluate 2 different depths. We know that as the depth increases we can get a more complex model and possible overfit. Let's review a max_depth of 5 and 15 to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d5f6264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Desision_Tree depth 5: 19.99\n",
      "R-squared decision tree depth 5: 0.93\n",
      "MAPE decision tree depth 5: 0.77%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# let's train the model\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# now, we'll predict the values for the output with the cross validation set\n",
    "y_hat_dt = tree_reg.predict(X_cv)\n",
    "\n",
    "# and finally we can evaluate the MSE and R-squared for the prediction\n",
    "mse_dt = (np.square(y_hat_dt - y_cv)).mean(axis=0)\n",
    "r_2_dt = np.corrcoef(y_cv,y_hat_dt)[0,1]**2\n",
    "mape_dt = mean_absolute_percentage_error(y_cv,y_hat_dt)\n",
    "\n",
    "print(f\"MSE Desision_Tree depth 5: {mse_dt:.2f}\")\n",
    "print(f\"R-squared decision tree depth 5: {r_2_dt:.2f}\")\n",
    "print(f\"MAPE decision tree depth 5: {mape_dt:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "109909d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Desision_Tree depth 15: 19.06\n",
      "R-squared decision tree depth 15: 0.94\n",
      "MAPE decision tree depth 15: 0.67%\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "tree_reg = DecisionTreeRegressor(max_depth=15)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# now, we'll predict the values for the output with the cross validation set\n",
    "y_hat_dt = tree_reg.predict(X_cv)\n",
    "\n",
    "# and finally we can evaluate the MSE and R-squared for the prediction\n",
    "mse_dt = (np.square(y_hat_dt - y_cv)).mean(axis=0)\n",
    "r_2_dt = np.corrcoef(y_cv,y_hat_dt)[0,1]**2\n",
    "mape_dt = mean_absolute_percentage_error(y_cv,y_hat_dt)\n",
    "\n",
    "print(f\"MSE Desision_Tree depth 15: {mse_dt:.2f}\")\n",
    "print(f\"R-squared decision tree depth 15: {r_2_dt:.2f}\")\n",
    "print(f\"MAPE decision tree depth 15: {mape_dt:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6224e",
   "metadata": {},
   "source": [
    "We can see that the MSE is reduced from the one obtained with a simple Linear Regression and that we can further improve the performance by increasing the depth. However, the performance is not particularly better than the one we can achieve with a simple Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dcabb",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "We will now try a Random Forest regression with 500 trees and a maximum of 20 values on terminal nodes. We should expect better performance as we increase the number of trees to use and less overfitting as we increase the number of leaves at the terminal nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4e1cb45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Random Forest: 19.08\n",
      "R-squared Random Forest: 0.94\n",
      "MAPE Random Forest: 0.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# let's train the model\n",
    "rnd_fst = RandomForestRegressor(n_estimators = 500, max_leaf_nodes=20, n_jobs=-1)\n",
    "rnd_fst.fit(X_train, y_train)\n",
    "\n",
    "# now, we'll predict with the cross validation set\n",
    "y_hat_rnd_fst = rnd_fst.predict(X_cv)\n",
    "\n",
    "# evaluate the MSE and R-squared for the prediction\n",
    "mse_rnd = (np.square(y_hat_rnd_fst - y_cv)).mean(axis=0)\n",
    "r_2_rnd = np.corrcoef(y_cv,y_hat_rnd_fst)[0,1]**2\n",
    "mape_rnd = mean_absolute_percentage_error(y_cv,y_hat_rnd_fst)\n",
    "\n",
    "print(f\"MSE Random Forest: {mse_rnd:.2f}\")\n",
    "print(f\"R-squared Random Forest: {r_2_rnd:.2f}\")\n",
    "print(f\"MAPE Random Forest: {mape_rnd:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e05be3",
   "metadata": {},
   "source": [
    "We can see that the performance is good but does not improve much from the Decision Trees with the best performance found previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0740618",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "Now we'll try the XGBoost algorithm which uses shallow trees in sequence to improve the errors of previous trees in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c3347a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE XGBoost: 10.11\n",
      "R-squared XGBoost: 0.97\n",
      "MAPE XGBoost: 0.51%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# let's train the model\n",
    "xgb_tree = XGBRegressor()\n",
    "xgb_tree.fit(X_train, y_train)\n",
    "\n",
    "# now, we'll predict with the cross validation set\n",
    "y_hat_xgb = xgb_tree.predict(X_cv)\n",
    "\n",
    "# evaluate the MSE and R-squared for the prediction\n",
    "mse_xgb = (np.square(y_hat_xgb - y_cv)).mean(axis=0)\n",
    "r_2_xgb = np.corrcoef(y_cv,y_hat_xgb)[0,1]**2\n",
    "mape_xgb = mean_absolute_percentage_error(y_cv,y_hat_xgb)\n",
    "\n",
    "print(f\"MSE XGBoost: {mse_xgb:.2f}\")\n",
    "print(f\"R-squared XGBoost: {r_2_xgb:.2f}\")\n",
    "print(f\"MAPE XGBoost: {mape_xgb:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c168b65",
   "metadata": {},
   "source": [
    "We can see that this algorithm greatly improves both on the level of error and the variance captured by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f51ce",
   "metadata": {},
   "source": [
    "### 5) Final model - performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7396e466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE XGBoost test: 10.96\n",
      "R-squared XGBoost test: 0.96\n",
      "MAPE XGBoost test: 0.50%\n"
     ]
    }
   ],
   "source": [
    "# test output with test set\n",
    "y_hat = xgb_tree.predict(X_test)\n",
    "\n",
    "# evaluate the MSE and R-squared for the prediction\n",
    "mse = (np.square(y_hat - y_test)).mean(axis=0)\n",
    "r_2 = np.corrcoef(y_test,y_hat)[0,1]**2\n",
    "mape = mean_absolute_percentage_error(y_test,y_hat)\n",
    "\n",
    "print(f\"MSE XGBoost test: {mse:.2f}\")\n",
    "print(f\"R-squared XGBoost test: {r_2:.2f}\")\n",
    "print(f\"MAPE XGBoost test: {mape:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de35a489",
   "metadata": {},
   "source": [
    "We see that the performance does not decrease relevantly from the cross valuation set.\n",
    "\n",
    "#### **Is a tree-based algorithm a good solution for this problem?**\n",
    "\n",
    "We know that tree-based models are not hard to train and are quite useful when we don't have extensive data. These models will capture patterns easily even in small data sets like this one.\n",
    "\n",
    "However, we also know that, given the way tree-based algorithms work, they might not extrapolate well when input data falls beyond the boundaries defined by the training set. \n",
    "\n",
    "In this case, we can rely on the fact that we are trying to predict the output of a machine and it can be safe to assume that we need the algorithm to predict behaviour within the boundaries defined by a normal operation. If the data set includes sufficient data to properly reflect normal working conditions, then this algorithm should provide a good solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
